# -*- coding: utf-8 -*-
ProjectDatascience.ipynb

Automatically generated by Colab.


# 1. Business Objective

The goal of this project is to analyze patient drug reviews and classify the patients medical condition based on the review text.
By understanding patient experiences, we can assess drug effectiveness and side effects and support better treatment recommendations.

Target Conditions

Depression

High Blood Pressure

Diabetes, Type 2

## 2. Dataset Description

Attributes

DrugName: Name of the drug

condition: Medical condition

review: Patient review (text)

# =========================
# Patient Condition Classification App
# =========================

import streamlit as st
import pandas as pd
import numpy as np
import re
import pickle

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

# -------------------------
# App Title
# -------------------------
st.title("Patient Condition Classification Using Drug Reviews")

# -------------------------
# Load Dataset
# -------------------------
@st.cache_data
def load_data():
    return pd.read_excel("drugsCom_raw.xlsx")

df = load_data()

# -------------------------
# Filter Required Conditions
# -------------------------
conditions = ['Depression', 'High Blood Pressure', 'Diabetes, Type 2']
df = df[df['condition'].isin(conditions)]

# -------------------------
# Text Cleaning Function (NO NLTK)
# -------------------------
def clean_text(text):
    text = str(text).lower()
    text = re.sub('[^a-z ]', '', text)
    words = text.split()
    words = [w for w in words if w not in ENGLISH_STOP_WORDS]
    return ' '.join(words)

df['clean_review'] = df['review'].apply(clean_text)

# -------------------------
# EDA Section
# -------------------------
st.subheader("Exploratory Data Analysis")

fig1, ax1 = plt.subplots()
sns.countplot(data=df, x='condition', ax=ax1)
ax1.set_title("Condition Distribution")
st.pyplot(fig1)

fig2, ax2 = plt.subplots()
ax2.hist(df['rating'], bins=10)
ax2.set_title("Rating Distribution")
st.pyplot(fig2)

df['review_length'] = df['review'].apply(lambda x: len(str(x).split()))
fig3, ax3 = plt.subplots()
ax3.hist(df['review_length'], bins=50)
ax3.set_title("Review Length Distribution")
st.pyplot(fig3)

# -------------------------
# Model Training
# -------------------------
X = df['clean_review']
y = df['condition']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

model = LogisticRegression(max_iter=1000)
model.fit(X_train_tfidf, y_train)

# -------------------------
# Evaluation
# -------------------------
st.subheader("Model Evaluation")

y_pred = model.predict(X_test_tfidf)
st.text(classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
fig4, ax4 = plt.subplots()
sns.heatmap(cm, annot=True, fmt='d',
            xticklabels=conditions,
            yticklabels=conditions, ax=ax4)
ax4.set_xlabel("Predicted")
ax4.set_ylabel("Actual")
st.pyplot(fig4)

# -------------------------
# Prediction Section
# -------------------------
st.subheader("Predict Patient Condition")

user_review = st.text_area("Enter patient review:")

if st.button("Predict"):
    cleaned = clean_text(user_review)
    vector = tfidf.transform([cleaned])
    prediction = model.predict(vector)[0]
    st.success(f"Predicted Condition: {prediction}")

